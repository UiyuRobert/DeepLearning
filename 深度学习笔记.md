# 深度学习笔记

## 1 基础数据操作

访问元素时，有如下操作（一列：`[:,1]`）：

![image-20250915094539729](assets/image-20250915094539729.png)

### 高级索引

```python
y = torch.tensor([0, 2])  # 真实标签
y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])  # 预测概率
result = y_hat[[0, 1], y]  # 高级索引
```

#### 1. 张量形状理解

- `y_hat`: 形状为 `(2, 3)` 的矩阵，表示2个样本的3个类别的预测概率
  - 第一行 `[0.1, 0.3, 0.6]`: 第一个样本的预测概率
  - 第二行 `[0.3, 0.2, 0.5]`: 第二个样本的预测概率
- `y`: 形状为 `(2,)` 的向量，表示2个样本的真实类别索引
  - `[0, 2]`: 第一个样本的真实类别是0，第二个样本的真实类别是2

#### 2. 索引操作 `y_hat[[0, 1], y]`

这是**同时指定行索引和列索引**的高级索引方式：

- **行索引**: `[0, 1]` → 选择第0行和第1行
- **列索引**: `y` 即 `[0, 2]` → 选择第0列和第2列

具体的索引对应关系：

- 取 `y_hat[0, y[0]]` = `y_hat[0, 0]` = `0.1`
- 取 `y_hat[1, y[1]]` = `y_hat[1, 2]` = `0.5`

#### 3. 最终结果

```python
print(result)  # 输出: tensor([0.1000, 0.5000])
```

#### 4. 注意

在 PyTorch 中，`len(X)` 的结果是 X 第一个维度的大小，相当于 `X.shape[0]`

### `argmax(axis=?)`

- **argmax** = argument of the maximum
- 返回**最大值所在位置的索引**，而不是最大值本身
- `axis` 参数指定沿着哪个维度进行操作

#### axis=0 的含义

- 在PyTorch中，`axis=0` 通常表示**沿着行的方向**（向下）操作
- 对于二维张量（矩阵），`axis=0` 意味着**按列操作**

#### 二维张量示例

```python
import torch

# 创建一个3x4的矩阵
tensor = torch.tensor([[1, 5, 3, 7],
                       [8, 2, 6, 4],
                       [3, 9, 1, 5]])

print("Original tensor:")
print(tensor)
print("Shape:", tensor.shape)  # torch.Size([3, 4])

result = tensor.argmax(axis=0)
print("argmax(axis=0) result:", result)  # 输出: tensor([1, 2, 1, 0])
```

## 2 PyTorch 数据操作

### `torch.utils.data.TensorDataset`

一个非常实用的数据集封装类，用于将多个张量组合成一个统一的数据集接口

```python
from torch.utils.data import TensorDataset
import torch

# 创建示例数据
features = torch.randn(100, 5)  # 100个样本，5个特征
labels = torch.randint(0, 2, (100,))  # 100个标签

# 创建 TensorDataset
dataset = TensorDataset(features, labels)
```

### `torch.rand()`

- **`torch.rand()`**：生成在 **`[0, 1)` 区间均匀分布**的随机数

```python
torch.rand(*size, *, out=None, dtype=None, layout=torch.strided, 
           device=None, requires_grad=False)
```

### `torch.randn()`

- **`torch.randn()`**：生成服从 **标准正态分布（均值为0，方差为1）** 的随机数

```python
torch.randn(*size, *, out=None, dtype=None, layout=torch.strided, 
           device=None, requires_grad=False) → Tensor

# 生成标量（0维张量）
x = torch.randn(())
print(x)  # 例如: tensor(0.1234)

# 生成1维张量（向量）
x = torch.randn(5)
print(x)  # 例如: tensor([-0.2345, 1.5678, 0.8765, -1.2345, 0.5432])

# 生成2维张量（矩阵）
x = torch.randn(3, 4)
print(x)
```

### `torch.randint()`

用于生成在指定范围内均匀分布的随机整数的函数，定义如下：

```python
torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
```

- **`low` (int, optional)**: 产生随机整数范围的**下限**（包含）。默认值是 `0`。
- **`high` (int)**: 产生随机整数范围的**上限**（**不包含**）。这是一个必须指定的参数。
- **`size` (tuple of ints)**: 定义了输出张量的**形状**。例如，`size=(2, 3)` 会生成一个 2行3列 的矩阵；`size=(5,)` 会生成一个长度为5的向量。

### `torch.utils.data.DataLoader`

负责高效地加载和预处理数据，并将其组织成批次供模型训练使用。

```python
DataLoader(
    dataset,            # 必须：Dataset对象
    batch_size=1,       # 批次大小
    shuffle=False,      # 是否打乱数据（训练集通常为True，测试集为False）
    num_workers=0,      # 加载数据的进程数（0=主进程，建议设为CPU核心数）
    pin_memory=False,   # 是否锁页内存，GPU训练时建议为True
    drop_last=False,    # 是否丢弃最后一个不完整的批次
)

import torch
from torch.utils.data import DataLoader, TensorDataset

# 1. 准备数据（这里用虚拟数据示例）
x = torch.randn(100, 3, 32, 32)  # 100个样本，3通道，32x32图像
y = torch.randint(0, 10, (100,))  # 100个标签

# 2. 创建 Dataset（这里使用TensorDataset）
dataset = TensorDataset(x, y)

# 3. 创建 DataLoader
dataloader = DataLoader(
    dataset=dataset,
    batch_size=32,      # 每个批次的样本数
    shuffle=True,       # 是否打乱数据
    num_workers=2       # 使用几个进程加载数据
)

# 4. 在训练循环中使用
for epoch in range(3):
    for batch_idx, (data, target) in enumerate(dataloader):
        # data.shape: torch.Size([32, 3, 32, 32])
        # target.shape: torch.Size([32])
        print(f'Epoch: {epoch}, Batch: {batch_idx}, Data shape: {data.shape}')
        
        # 这里通常是训练代码：
        # optimizer.zero_grad()
        # output = model(data)
        # loss = criterion(output, target)
        # loss.backward()
        # optimizer.step()
```

### `torch.arange()`

#### 1. 函数概述

`torch.arange()` 是 PyTorch 中用于**创建等差数列张量**的函数，类似于 Python 内置的 `range()` 函数，但返回的是张量。

#### 2. 基本语法

```python
torch.arange(start=0, end, step=1, *, out=None, dtype=None, 
             layout=torch.strided, device=None, requires_grad=False)
```

#### 3. 参数详解

| 参数            | 说明                 | 默认值       |
| --------------- | -------------------- | ------------ |
| **`start`**     | 序列起始值（包含）   | `0`          |
| **`end`**       | 序列结束值（不包含） | **必须指定** |
| **`step`**      | 步长（公差）         | `1`          |
| `dtype`         | 输出张量的数据类型   | 根据输入推断 |
| `device`        | 张量存储设备         | 当前设备     |
| `requires_grad` | 是否需要梯度         | `False`      |

#### 4. 基本使用示例

##### 4.1 最简单的用法
```python
import torch

# 从0到4（不包含5）
a = torch.arange(5)
print(a)  # tensor([0, 1, 2, 3, 4])

# 指定起始和结束
b = torch.arange(2, 8)
print(b)  # tensor([2, 3, 4, 5, 6, 7])

# 指定步长
c = torch.arange(1, 10, 2)
print(c)  # tensor([1, 3, 5, 7, 9])
```

##### 4.2 浮点数序列
```python
# 浮点数序列
d = torch.arange(0.0, 2.5, 0.5)
print(d)  # tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000])

# 负步长（递减序列）
e = torch.arange(5, 0, -1)
print(e)  # tensor([5, 4, 3, 2, 1])
```

### `normal_()`

#### 1. 定义

```python
normal_(mean=0, std=1, *, generator=None) -> Tensor
```

- **`normal`**：指的是**正态分布**（也叫高斯分布），这是概率论和统计学中最重要的一种连续概率分布。
- **下划线 `_`**：在 PyTorch 中，函数名后面带下划线表示这是一个**原地操作（in-place operation）**。意思是这个函数会**直接修改调用它的张量本身**，而不是返回一个新的张量。

所以 `normal_()` 的意思是："用正态分布的值来填充这个张量本身"。

#### 2. 参数解释

- **`mean=0`**：正态分布的**均值**（平均值）。分布的中心位置，默认为0。
- **`std=1`**：正态分布的**标准差**。表示数据的离散程度，默认为1。
- **`generator=None`**：用于控制随机数生成的生成器。如果提供，可以确保随机性的可重复性（用于实验复现）。

### `fill_()`

`fill_()` 是 PyTorch 张量的一个**原地操作（in-place operation）** 方法，用于将张量的**所有元素**设置为指定的标量值。

```python
fill_(value) -> Tensor
```

- **`fill`**：表示"填充"的意思
- **下划线 `_`**：表示这是一个原地操作，会直接修改调用它的张量本身

### `type()`

`tensor.type()` 用于**获取张量的数据类型**或者**转换张量的数据类型**。

```python
################# 获取数据类型
import torch

# 创建不同数据类型的张量
tensor_int = torch.tensor([1, 2, 3])
tensor_float = torch.tensor([1.0, 2.0, 3.0])
tensor_double = torch.tensor([1.0, 2.0, 3.0], dtype=torch.double)

print(tensor_int.type())    # 输出: torch.LongTensor
print(tensor_float.type())  # 输出: torch.FloatTensor
print(tensor_double.type()) # 输出: torch.DoubleTensor

################## 转换数据类型
# 创建浮点数张量
tensor = torch.tensor([1.5, 2.3, 3.7])
print("Original type:", tensor.type())  # torch.FloatTensor

# 转换为整数类型
tensor_int = tensor.type(torch.LongTensor)
print("Converted type:", tensor_int.type())  # torch.LongTensor
print("Values:", tensor_int)  # tensor([1, 2, 3]) - 小数部分被截断

######################## 使用dtype参数（更现代的方式）

# 推荐使用.to()方法进行类型转换
tensor = torch.tensor([1.5, 2.3, 3.7])

# 各种转换方式
tensor_int = tensor.to(torch.int32)
tensor_float = tensor.to(torch.float64)
tensor_double = tensor.to(torch.double)

print(tensor_int.dtype)   # torch.int32
print(tensor_float.dtype) # torch.float64
```



## 3 `torch.nn`

### `torch.nn.MSELoss`

#### 1. 定义

`nn.MSELoss` 是 PyTorch 中用于计算**均方误差（Mean Squared Error, MSE）** 的损失函数类。它是回归问题中最常用、最基础的损失函数之一。

**MSE 的数学定义：**

```
MSE = (1/n) * Σ(y_pred - y_true)²
```

其中：

- `y_pred` 是模型的预测值
- `y_true` 是真实的目标值
- `n` 是样本数量
- `Σ` 表示求和

MSE 衡量的是**预测值与真实值之间差异的平方的平均值**。它惩罚较大的误差更为严重（因为平方操作），这使得模型更倾向于避免产生大的预测误差。

#### 2. 参数

```python
torch.nn.MSELoss(reduction='mean')
```

**主要参数：**

- **`reduction`** (字符串)：指定缩减方式，这是最重要的参数
  - **`'mean'`**：默认值。计算所有元素的平均值 `(1/n) * Σloss`
  - **`'sum'`**：计算所有元素的和 `Σloss`
  - **`'none'`**：不进行缩减，返回与输入相同形状的损失张量

### `nn.CrossEntropyLoss`

#### 1. 什么是 `CrossEntropyLoss`？

`nn.CrossEntropyLoss` 结合了 **Softmax 激活函数** 和 **负对数似然损失（NLLLoss）**，专门用于**多分类问题**。它衡量模型预测的概率分布与真实标签分布之间的差异。

#### 2. 数学原理

##### 2.1 交叉熵公式
对于单个样本：
$$
\text{Loss} = -\sum_{c=1}^{C} y_c \cdot \log(p_c)
$$

其中：
- $C$：类别数量
- $y_c$：真实标签的one-hot编码（第c类为1，其余为0）
- $p_c$：模型预测的第c类的概率

##### 2.2 实际计算过程
由于真实标签通常是类别索引而不是one-hot编码，PyTorch使用：
$$
\text{Loss} = -\log\left(\frac{\exp(x_{\text{class}})}{\sum_j \exp(x_j)}\right)
= -x_{\text{class}} + \log\left(\sum_j \exp(x_j)\right)
$$

#### 3. 参数详解

```python
nn.CrossEntropyLoss(weight=None, 
                   ignore_index=-100, 
                   reduction='mean')
```

| 参数               | 说明                                   | 默认值 |
| ------------------ | -------------------------------------- | ------ |
| **`weight`**       | 各类别的权重张量（用于处理类别不平衡） | `None` |
| **`reduction`**    | 损失 reduction 方式：`none`            | `mean` |
| **`ignore_index`** | 忽略的标签索引（不参与损失计算）       | `-100` |

#### 4. 输入要求

##### 4.1 模型输出（Input）
- **形状**: `[batch_size, num_classes]`
- **内容**: 原始的**未经过Softmax的分数**（logits）
- **不需要**手动进行Softmax，损失函数内部会处理

##### 4.2 真实标签（Target）Softmax的分数
- **形状**: `[batch_size]`
- **内容**: 每个样本的**类别索引**（0到num_classes-1）
- **或者**: `[batch_size, num_classes]`（class probabilities，较少用）

#### 5. 基本使用示例

##### 示例1：最简单的用法
```python
import torch
import torch.nn as nn

# 定义损失函数
criterion = nn.CrossEntropyLoss()

# 模拟数据：batch_size=4，3个类别
logits = torch.tensor([[2.0, 1.0, 0.1],  # 模型输出（未softmax）
                       [1.0, 2.0, 0.1],
                       [0.1, 1.0, 2.0],
                       [1.0, 0.1, 2.0]])

labels = torch.tensor([0, 1, 2, 2])  # 真实标签索引

# 计算损失
loss = criterion(logits, labels)
print(f"Loss: {loss.item():.4f}")  # 输出: Loss: 0.7858
```

### `nn.Linear`

#### 1. 它是什么？

`nn.Linear` 是 PyTorch 的 `torch.nn` 模块中的一个类，它用于定义一个**全连接层**（Fully Connected Layer），也叫**线性层**或**仿射变换层**。

它的核心作用就是执行一个**线性变换**：

```
输出 = 输入 · 权重^T + 偏置
```

- `权重^T` 表示权重的转置。这是为了满足矩阵乘法的维度要求。
- 如果设置了 `bias=False`，则没有 `+ 偏置` 这一步。

#### 2. 语法和参数

python

```python
torch.nn.Linear(in_features, out_features, bias=True)
```

- **`in_features`**： 每个输入样本的特征数量（即输入张量最后一个维度的大小）。
- **`out_features`**： 每个输出样本的特征数量（即输出张量最后一个维度的大小）。
- **`bias`**： 一个布尔值。如果设置为 `False`，该层将不会学习一个附加的偏置项。默认为 `True`。

#### 3. 它的工作方式（输入和输出形状）

- **输入形状**: `(*, H_in)`
  - 这里的 `*` 表示可以有任意多个维度（例如，`(batch_size, H_in)` 或 `(batch_size, seq_len, H_in)` 等）。
  - `H_in` 必须等于 `in_features`。
- **输出形状**: `(*, H_out)`
  - 除了最后一个维度被变换为 `H_out`（即 `out_features`）外，所有其他维度都保持不变。

**最常见的情况**：输入是一个二维张量，形状为 `(N, C_in)`，其中 `N` 是批次大小（batch size），`C_in` 是特征数。
那么输出就是一个二维张量，形状为 `(N, C_out)`。

#### 4. 内部参数

一个 `nn.Linear` 模块包含两个可学习的参数：

- **`weight`**: 权重矩阵，形状为 `(out_features, in_features)`。
- **`bias`**: 偏置向量，形状为 `(out_features,)`（如果 `bias=True`）。

这些参数在模块初始化时被随机初始化（例如使用 Kaiming 或 Xavier 初始化方法），并在模型训练过程中通过反向传播不断更新。

你可以通过 `linear_layer.weight` 和 `linear_layer.bias` 来访问它们。

#### 5. 简单代码示例

让我们通过几个例子来直观地理解它。

**示例 1：基础用法**

```python
import torch
import torch.nn as nn

# 定义一个线性层：输入特征数为 5，输出特征数为 3
linear_layer = nn.Linear(in_features=5, out_features=3, bias=True)

# 创建一个随机输入张量，形状为 (batch_size, in_features) = (2, 5)
input_tensor = torch.randn(2, 5)
print("Input shape:", input_tensor.shape) # torch.Size([2, 5])

# 将输入传递给线性层
output_tensor = linear_layer(input_tensor)
print("Output shape:", output_tensor.shape) # torch.Size([2, 3])

# 查看内部参数
print("Weight shape:", linear_layer.weight.shape) # torch.Size([3, 5])
print("Bias shape:", linear_layer.bias.shape)   # torch.Size([3])
```



**示例 2：验证计算过程**

我们可以手动进行矩阵乘法来验证 `nn.Linear` 的结果。

```python
import torch
import torch.nn as nn

# 为了复现结果，设置随机种子
torch.manual_seed(42)

# 定义一个非常小的层
linear_layer = nn.Linear(2, 1, bias=True)
print("Initial weight:", linear_layer.weight) # e.g., tensor([[0.6641, 0.1634]])
print("Initial bias:", linear_layer.bias)   # e.g., tensor([-0.3561])

# 创建一个简单的输入
input_tensor = torch.tensor([[1.0, 2.0]])
output = linear_layer(input_tensor)
print("Output from nn.Linear:", output) # e.g., tensor([[0.8980]])

# 手动计算验证
manual_output = torch.matmul(input_tensor, linear_layer.weight.T) + linear_layer.bias
print("Manual calculation:", manual_output) # e.g., tensor([[0.8980]])

# 检查两者是否相等（允许微小的浮点数误差）
print("Are they close?", torch.allclose(output, manual_output)) # True
```



**示例 3：更高维度的输入**

`nn.Linear` 只对最后一个维度进行操作，前面的维度都会被保留。

```python
import torch
import torch.nn as nn

linear_layer = nn.Linear(10, 5)

# 输入一个三维张量，形状为 (batch_size, sequence_length, features)
# 常见于处理序列数据的RNN/LSTM/Transformer模型
input_3d = torch.randn(4, 7, 10) # (batch_size=4, seq_len=7, in_features=10)
output_3d = linear_layer(input_3d)
print("3D Input shape:", input_3d.shape)  # torch.Size([4, 7, 10])
print("3D Output shape:", output_3d.shape) # torch.Size([4, 7, 5]) features从10变为了5

# 输入一个四维张量（例如，卷积特征图展平后的结果）
input_4d = torch.randn(4, 16, 8, 10) # 假设 16*8=128个空间位置，每个位置有10个特征
output_4d = linear_layer(input_4d)
print("4D Input shape:", input_4d.shape)  # torch.Size([4, 16, 8, 10])
print("4D Output shape:", output_4d.shape) # torch.Size([4, 16, 8, 5])
```

#### 6. 在神经网络中的使用

`nn.Linear` 是构建深度学习模型最基础的积木块，几乎无处不在。

```python
import torch.nn as nn

class SimpleNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(SimpleNet, self).__init__()
        # 第一个全连接层：input_size -> hidden_size
        self.fc1 = nn.Linear(input_size, hidden_size)
        # 激活函数，引入非线性
        self.relu = nn.ReLU()
        # 第二个全连接层（输出层）：hidden_size -> num_classes
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

# 实例化模型
model = SimpleNet(input_size=784, hidden_size=500, num_classes=10)
# 输入一个MNIST图片（展平为784维向量）
x = torch.randn(64, 784) # batch_size=64
output = model(x)
print(output.shape) # torch.Size([64, 10])
```

### `nn.Flatten`

#### 1. 它是什么？

`nn.Flatten` 是 PyTorch 神经网络模块 (`torch.nn`) 中的一个**层**。它的作用非常直观：**将一个多维的输入张量“压平”成一个一维或二维的张量**。

在神经网络中，这通常用于从卷积层（输出多维特征图）过渡到全连接层（需要一维输入）的时候。

#### 2. 为什么需要它？

想象一个典型的卷积神经网络 (CNN) 结构：
1.  **输入**：一张图片，其维度为 `[批次大小, 通道数, 高度, 宽度]`，例如 `[32, 3, 64, 64]`（32张图片，每张3个颜色通道，高64像素，宽64像素）。
2.  **卷积层和池化层**：这些层处理数据后，输出的仍然是一个多维张量，例如 `[32, 128, 16, 16]`（32个样本，128个特征通道，高16像素，宽16像素）。
3.  **全连接层**：全连接层要求它的输入是一个一维的向量。它无法直接处理 `[32, 128, 16, 16]` 这样的四维张量。

这时，`nn.Flatten` 就派上了用场。它可以将 `[32, 128, 16, 16]` 这个四维张量，转换成一个二维张量 `[32, 128 * 16 * 16]`，也就是 `[32, 32768]`。
- 第一个维度 (`32`) 是**批次大小**，保持不变。
- 后面所有的维度 (`128, 16, 16`) 都被**乘在一起**，“压平”成了第二个维度 (`32768`)。
这个二维张量就可以顺利送入全连接层了（第一维是 batch，第二维是特征）。

#### 3. 如何使用它？

##### 初始化参数
```python
torch.nn.Flatten(start_dim=1, end_dim=-1)
```
- **`start_dim`**：开始“压平”的维度（从哪个维度开始，包含该维度）。**默认为 1**。这是因为通常第0维是批次大小 (batch size)，我们希望保留它，而从第1维开始压平。
- **`end_dim`**：结束“压平”的维度（到哪个维度结束，包含该维度）。**默认为 -1**，即最后一个维度。

##### 基本使用示例

```python
import torch
import torch.nn as nn

# 示例1：经典用法，为全连接层准备数据
flatten_layer = nn.Flatten()
# 模拟一个卷积层输出的特征图
input_tensor = torch.randn(32, 128, 16, 16) # [batch, channel, height, width]
output = flatten_layer(input_tensor)

print(input_tensor.shape) # torch.Size([32, 128, 16, 16])
print(output.shape)       # torch.Size([32, 32768]) 
                         # 因为 128 * 16 * 16 = 32768
```

##### 使用 `start_dim` 和 `end_dim` 的示例

```python
# 示例2：一个三维张量
input_3d = torch.randn(4, 3, 10) # [batch, feature_A, feature_B]

# 默认情况 (start_dim=1): 从第1维开始压平到最后一维
flatten_default = nn.Flatten()
output_default = flatten_default(input_3d)
print(output_default.shape) # torch.Size([4, 30]) 
                           # 因为 3 * 10 = 30

# 从第0维开始压平
flatten_from_0 = nn.Flatten(start_dim=0)
output_from_0 = flatten_from_0(input_3d)
print(output_from_0.shape) # torch.Size([120]) 
                          # 因为 4 * 3 * 10 = 120，所有维度都被压平了

# 只压平特定的中间维度 (从第1维到第1维)
flatten_specific = nn.Flatten(start_dim=1, end_dim=1)
output_specific = flatten_specific(input_3d)
print(output_specific.shape) # torch.Size([4, 3, 10]) 
                            # 形状不变，因为从1到1维，相当于没压平

# 压平最后两维
input_4d = torch.randn(5, 2, 3, 4) # [dim0, dim1, dim2, dim3]
flatten_last_two = nn.Flatten(start_dim=2) # 从第2维开始压平到最后一维(-1)
output_last_two = flatten_last_two(input_4d)
print(output_last_two.shape) # torch.Size([5, 2, 12]) 
                            # dim2和dim3被合并：3 * 4 = 12
```

#### 4. 在神经网络模型中的用法

在定义 PyTorch 模型时，你通常会把它放在卷积层/池化层和全连接层之间。

```python
class MyCNN(nn.Module):
    def __init__(self):
        super(MyCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),
        )
        # 在这里，我们不知道卷积层输出的具体尺寸，但可以用Flatten来处理
        self.flatten = nn.Flatten()
        self.classifier = nn.Sequential(
            nn.Linear(in_features=32 * 6 * 6, out_features=128), # 需要计算压平后的尺寸
            nn.ReLU(),
            nn.Linear(128, 10) # 假设是10分类任务
        )

    def forward(self, x):
        x = self.features(x)
        # print(x.shape) # 在第一次运行时可以打印出形状，以便确定Linear层的输入大小
        x = self.flatten(x)
        x = self.classifier(x)
        return x
```
**注意**：在上面的例子中，全连接层 `nn.Linear` 的 `in_features` 需要你根据卷积层输出的尺寸手动计算（例如 `32 * 6 * 6`）。一个常见的技巧是先让模型跑一次，通过 `print(x.shape)` 查看 `Flatten` 层之前的张量形状，然后再确定 `in_features` 的值。

#### 总结

| 特性         | 说明                                                         |
| :----------- | :----------------------------------------------------------- |
| **目的**     | 连接卷积层和全连接层，将多维输入转换为低维输入。             |
| **默认行为** | 保留第0维（批次维度），将之后的所有维度展平。                |
| **关键参数** | `start_dim`：指定从哪个维度开始展平。`end_dim`：指定到哪个维度结束。 |
| **输出形状** | `[batch_size, dim_i * dim_i+1 * ... * dim_n]`                |

简单来说，**`nn.Flatten` 就是一个负责“降维”的层，是构建CNN模型时不可或缺的桥梁**。

### `nn.Sequential`

#### 1. 它是什么？

`nn.Sequential` 是一个**容器（Container）模块**，它允许你将多个网络模块**按顺序**组合在一起，形成一个更大的模块。数据会按照你在 Sequential 中定义的顺序，依次通过每一个子模块。

可以把它想象成一个**流水线**或者**一叠积木**：输入数据从一端进入，依次经过每个处理步骤，最后从另一端输出。

#### 2. 为什么需要它？

在没有 `nn.Sequential` 的情况下，构建一个简单的多层网络需要在 `forward` 函数中手动调用每一层：

```python
class MyNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x))) # 手动调用每一层
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
```

使用 `nn.Sequential` 可以：
1.  **简化代码**：避免在 `forward` 中写重复的调用语句。
2.  **提高可读性**：网络结构一目了然。
3.  **方便管理**：整个 Sequential 块被视为一个整体，可以轻松打印、遍历或提取特征。

#### 3. 语法和创建方式

有几种创建 `nn.Sequential` 的方法：

**方式一：按顺序直接传递模块（最常用）**
```python
model = nn.Sequential(
    nn.Linear(784, 256),
    nn.ReLU(),
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)
```

**方式二：使用 OrderedDict（推荐，可以命名每个层）**

```python
from collections import OrderedDict

model = nn.Sequential(OrderedDict([
    ('flatten', nn.Flatten()),
    ('fc1', nn.Linear(784, 256)),
    ('relu1', nn.ReLU()),
    ('dropout1', nn.Dropout(0.2)),
    ('fc2', nn.Linear(256, 128)),
    ('relu2', nn.ReLU()),
    ('fc3', nn.Linear(128, 10))
]))
```
这种方式的好处是每一层都有了一个名字，在打印模型或调试时非常清晰。

**方式三：使用 add_module 方法动态添加**
```python
model = nn.Sequential()
model.add_module('conv1', nn.Conv2d(3, 6, 5))
model.add_module('pool1', nn.MaxPool2d(2))
model.add_module('conv2', nn.Conv2d(6, 16, 5))
```

#### 4. 它的工作方式（前向传播）

`nn.Sequential` 的前向传播 `forward(x)` 非常简单：**按顺序**将输入 `x` 传递给它的第一个子模块，然后将结果传递给第二个子模块，依此类推，直到最后一个子模块产生输出。

```python
# 对于上面的第一个例子，这行代码：
output = model(input_data)

# 等价于手动执行了：
x = nn.Linear(784, 256)(input_data)
x = nn.ReLU()(x)
x = nn.Linear(256, 128)(x)
x = nn.ReLU()(x)
x = nn.Linear(128, 10)(x)
output = x
```

#### 5. 访问内部模块和参数

你可以像访问列表一样通过索引来访问 `nn.Sequential` 中的子模块，也可以通过你赋予的名字（如果使用了 OrderedDict 或 `add_module`）来访问。

```python
# 使用方式一的模型
print(model[0]) # 打印第一层: Linear(in_features=784, out_features=256, bias=True)
print(model[2]) # 打印第三层: Linear(in_features=256, out_features=128, bias=True)

# 使用方式二的模型（命名后）
print(model.fc1)    # 访问名为 'fc1' 的层
print(model.relu2)  # 访问名为 'relu2' 的层

# 遍历所有子模块
for name, module in model.named_children():
    print(f"Layer: {name} | Module: {module}")

# 获取第0层的参数
first_layer_weights = model[0].weight
```

#### 6. 完整代码示例

让我们看一个结合了卷积层和全连接层的完整 CNN 例子：

```python
import torch
import torch.nn as nn
from collections import OrderedDict

# 定义一个CNN模型，使用Sequential组织不同的部分
class CNN(nn.Module):
    def __init__(self, num_classes=10):
        super(CNN, self).__init__()
        
        # 特征提取部分 (卷积 -> 激活 -> 池化)
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        # 分类器部分 (全连接层)
        self.classifier = nn.Sequential(OrderedDict([
            ('dropout1', nn.Dropout(p=0.5)),
            ('fc1', nn.Linear(64 * 8 * 8, 512)), # 假设输入图像是32x32，经过两次池化后为8x8
            ('relu1', nn.ReLU(inplace=True)),
            ('dropout2', nn.Dropout(p=0.5)),
            ('fc2', nn.Linear(512, num_classes)),
        ]))

    def forward(self, x):
        x = self.features(x) # 数据流经features Sequential
        x = torch.flatten(x, 1) # 展平特征图
        x = self.classifier(x) # 数据流经classifier Sequential
        return x

# 创建模型实例
model = CNN(num_classes=10)
print(model)

# 创建一个随机输入（batch_size=4, 3通道, 32x32图像）
dummy_input = torch.randn(4, 3, 32, 32)
output = model(dummy_input)
print(f"Input shape: {dummy_input.shape}")
print(f"Output shape: {output.shape}") # 应该是 torch.Size([4, 10])
```

**输出示例：**
```
CNN(
  (features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (dropout1): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=4096, out_features=512, bias=True)
    (relu1): ReLU(inplace=True)
    (dropout2): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=512, out_features=10, bias=True)
  )
)
Input shape: torch.Size([4, 3, 32, 32])
Output shape: torch.Size([4, 10])
```

### `nn.init`

#### 1. 什么是 `nn.init`？

`nn.init` 是 PyTorch 的 `torch.nn` 模块中的一个子模块，专门用于**神经网络权重的初始化**。它提供了一系列的函数来用不同的分布或方法初始化张量（主要是权重和偏置参数）。

#### 2. 为什么需要权重初始化？

权重初始化对神经网络的训练至关重要，原因如下：

1. **打破对称性**：如果所有权重初始化为相同值，同一层的所有神经元会学习相同的特征，大大降低网络的表达能力。
2. **防止梯度消失/爆炸**：不合适的初始化可能导致梯度在反向传播时变得极小（消失）或极大（爆炸），使得网络无法训练。
3. **加速收敛**：合适的初始化可以让网络更快地收敛到好的解。
4. **训练稳定性**：良好的初始化可以提高训练的稳定性。

#### 3. 常用的初始化方法

##### 3.1 基于分布的初始化

###### a) 常数初始化
```python
# 将所有值初始化为常数0
nn.init.constant_(tensor, 0)

# 将权重初始化为1，偏置初始化为0
nn.init.constant_(layer.weight, 1)
nn.init.constant_(layer.bias, 0)
```

###### b) 均匀分布初始化
```python
# 从均匀分布 U(-a, a) 中采样
nn.init.uniform_(tensor, a=0, b=1)  # U(0, 1)
```

###### c) 正态分布初始化
```python
# 从正态分布 N(mean, std^2) 中采样
nn.init.normal_(tensor, mean=0, std=1)  # N(0, 1)
```

##### 3.2 基于理论的初始化（更常用）

###### a) Xavier/Glorot 初始化
适用于使用 `tanh`、`sigmoid` 等S型激活函数的层。

```python
# 均匀分布版本
nn.init.xavier_uniform_(tensor, gain=1.0)

# 正态分布版本  
nn.init.xavier_normal_(tensor, gain=1.0)

# gain参数根据激活函数调整：
# - tanh: gain=1.0 (默认)
# - sigmoid: gain=1.0
# - ReLU: gain=math.sqrt(2)
```

###### b) Kaiming/He 初始化
适用于使用 `ReLU` 及其变体的激活函数的层。

```python
# 均匀分布版本
nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='relu')

# 正态分布版本
nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='relu')

# 参数说明：
# - a: ReLU的负斜率（对于LeakyReLU）
# - mode: 'fan_in'（保持前向传播方差）或 'fan_out'（保持反向传播方差）
# - nonlinearity: 'relu', 'leaky_relu' 等
```

##### 3.3 其他特殊初始化

###### 正交初始化
```python
nn.init.orthogonal_(tensor, gain=1)
# 适用于RNN，有助于缓解梯度消失问题
```

###### 单位矩阵初始化
```python
nn.init.eye_(tensor)
# 将2D张量初始为单位矩阵
```

###### 稀疏初始化
```python
nn.init.sparse_(tensor, sparsity, std=0.01)
# 将大部分权重设为0，只有少量非零值
```

#### 4. 使用方法

##### 方法1：直接对张量初始化
```python
import torch.nn as nn

# 创建一个线性层
linear = nn.Linear(784, 256)

# 对权重使用Kaiming初始化
nn.init.kaiming_normal_(linear.weight, mode='fan_in', nonlinearity='relu')

# 对偏置使用常数初始化
nn.init.constant_(linear.bias, 0.0)
```

##### 方法2：使用 `apply()` 函数（推荐）
```python
def init_weights(m):
    if isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

# 应用到整个网络
model.apply(init_weights)
```

##### 方法3：在模块定义时初始化
```python
class MyNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(784, 256)
        self._init_weights()
    
    def _init_weights(self):
        nn.init.kaiming_normal_(self.linear.weight, nonlinearity='relu')
        nn.init.constant_(self.linear.bias, 0)
    
    def forward(self, x):
        return self.linear(x)
```

#### 5. 不同层类型的推荐初始化

| 层类型                      | 推荐初始化方法                              | 说明                |
| --------------------------- | ------------------------------------------- | ------------------- |
| **全连接层** + ReLU         | `kaiming_normal_`                           | 适合ReLU族激活函数  |
| **全连接层** + tanh/sigmoid | `xavier_normal_`                            | 适合S型激活函数     |
| **卷积层**                  | `kaiming_normal_`                           | 通常与ReLU配合使用  |
| **批归一化层**              | `constant_(weight, 1)` `constant_(bias, 0)` | 标准做法            |
| **LSTM/GRU**                | 通常使用内置初始化                          | 或使用`orthogonal_` |

### `nn.Parameter`

#### 1. 核心概念：它是什么？

`nn.Parameter` 是 PyTorch 中的一个类，它继承自 `torch.Tensor`。它的核心作用是**将一个普通的 Tensor 标记为模型的一个参数（Parameter）**。

**关键点：**
*   它是一个特殊的 Tensor。
*   当一个 Tensor 被包装成 `nn.Parameter` 后，它会被自动添加到其所属模块（`nn.Module`）的参数列表中。
*   这意味着在训练过程中，优化器（如 `torch.optim.SGD` 或 `Adam`）能够识别到这个 Tensor，并会**自动更新它的值（即进行梯度下降）**。

**简单来说：`nn.Parameter` 就是告诉 PyTorch：“这个 Tensor 是我的模型需要学习和更新的权重。”**

#### 2. 为什么需要它？（与普通 Tensor 的区别）

让我们通过一个对比来理解为什么 `nn.Parameter` 是必要的。

假设我们想创建一个简单的线性层：`y = w * x + b`，其中 `w` 和 `b` 是需要学习的参数。

**错误的方式（使用普通 Tensor）：**

```python
import torch
import torch.nn as nn

class BadLinearLayer(nn.Module):
    def __init__(self, input_size, output_size):
        super().__init__()
        # 错误：使用普通 Tensor
        self.weight = torch.randn(output_size, input_size)
        self.bias = torch.randn(output_size)

    def forward(self, x):
        return torch.mm(x, self.weight.t()) + self.bias

# 创建模型和优化器
model = BadLinearLayer(10, 5)
optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 注意这里用的是 model.parameters()

x = torch.randn(1, 10)
output = model(x)

# 计算损失并反向传播
loss = output.sum()
loss.backward()

print("Weight gradient:", self.weight.grad) # 输出：None
optimizer.step() # 这一步不会更新 self.weight 和 self.bias！
```

**问题出在哪？**
1.  当你调用 `model.parameters()` 时，PyTorch 只会查找那些被定义为 `nn.Parameter` 的属性。
2.  因为 `self.weight` 和 `self.bias` 是普通 Tensor，它们**不会**出现在 `model.parameters()` 返回的列表中。
3.  因此，优化器根本不知道它们的存在，自然不会为它们计算梯度，也不会在 `optimizer.step()` 时更新它们的值。

**正确的方式（使用 `nn.Parameter`）：**

```python
import torch
import torch.nn as nn

class GoodLinearLayer(nn.Module):
    def __init__(self, input_size, output_size):
        super().__init__()
        # 正确：使用 nn.Parameter 包装 Tensor
        self.weight = nn.Parameter(torch.randn(output_size, input_size))
        self.bias = nn.Parameter(torch.randn(output_size))

    def forward(self, x):
        return torch.mm(x, self.weight.t()) + self.bias

# 创建模型和优化器
model = GoodLinearLayer(10, 5)
optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 现在 model.parameters() 包含了 weight 和 bias

x = torch.randn(1, 10)
output = model(x)

# 计算损失并反向传播
loss = output.sum()
loss.backward()

# 现在梯度存在了
print("Weight gradient shape:", model.weight.grad.shape) # 例如：torch.Size([5, 10])
optimizer.step() # 成功更新了 self.weight 和 self.bias！
```

**结论：** 只有使用 `nn.Parameter`，你自定义的参数才能被 PyTorch 的自动梯度机制和优化器正确管理。

#### 3. 主要特性和行为

1.  **自动注册：** 当在 `nn.Module` 内将一个 `nn.Parameter` 赋值给一个属性时（例如 `self.weight = nn.Parameter(...)`），`nn.Module` 会自动将其加入到参数列表中。你可以通过 `model.parameters()` 或 `model.named_parameters()` 访问它们。
2.  **自动梯度计算：** 在反向传播时，PyTorch 会自动计算 `nn.Parameter` 的梯度，并将其存储在 `.grad` 属性中。
3.  **设备移动：** 当你调用 `model.to(device)`（如 `model.cuda()`）时，所有 `nn.Parameter` 都会被自动移动到对应的设备（CPU 或 GPU）上。
4.  **状态字典：** `nn.Parameter` 会被保存到模型的状态字典中（`model.state_dict()`），方便模型的保存和加载。

#### 4. 什么时候需要使用 `nn.Parameter`？

**你需要使用 `nn.Parameter` 的情况：**
*   **自定义层（Custom Layers）：** 当你自己实现一个包含可学习权重的神经网络层时（如上面的 `GoodLinearLayer` 例子）。
*   **向现有模块添加参数：** 例如，你想给一个预训练模型添加一个可学习的适配器或门控机制。

**你不需要显式使用 `nn.Parameter` 的情况：**
*   **使用内置模块：** 像 `nn.Linear`, `nn.Conv2d`, `nn.LSTM` 等 PyTorch 内置模块，它们内部的参数已经用 `nn.Parameter` 定义好了，你直接使用即可。
*   **中间变量或常量：** 那些不需要梯度、不需要优化的 Tensor（例如，一个固定的掩码或一个中间计算结果），应该使用普通 Tensor 或者用 `torch.no_grad()` 上下文管理器。

#### 总结

| 特性                                 | 普通 Tensor      | `nn.Parameter`  |
| :----------------------------------- | :--------------- | :-------------- |
| **是否被 `model.parameters()` 包含** | 否               | **是**          |
| **优化器是否会更新**                 | 否               | **是**          |
| **是否需要梯度（requires_grad）**    | 可 True 可 False | **默认为 True** |
| **设备移动（model.to(device)）**     | 不会自动移动     | **自动移动**    |
| **保存到 state_dict**                | 否               | **是**          |

**一句话总结：`nn.Parameter` 是定义模型可训练权重的标准方式，是连接你的自定义 Tensor 与 PyTorch 训练生态（自动求导、优化器、设备管理）的桥梁。**

### 特殊操作——模型模式设置

```python
if isinstance(net, torch.nn.Module):
    net.eval()  # 将模型设置为评估模式
```

**作用**：

- `isinstance(net, torch.nn.Module)`：检查 `net` 是否是PyTorch模型
- `net.eval()`：将模型切换到评估模式（与训练模式 `net.train()` 相对）

**为什么重要**：

- 评估模式下会禁用Dropout、BatchNorm等训练特有的层
- 确保评估结果的一致性

### 特殊操作——`eval()`、`train()`

`net.eval()` 用于将神经网络切换到**评估模式（evaluation mode）**。

PyTorch模型有两种运行模式：

1. **训练模式（training mode）**：`net.train()` - 默认模式
2. **评估模式（evaluation mode）**：`net.eval()`

通过 `net.train(), net.eval()` 进行切换

#### 为什么需要 `eval()`？

某些神经网络层在训练和评估时的行为是不同的：

1. Dropout 层

   - **训练时**：随机丢弃一部分神经元，防止过拟合

   - **评估时**：使用所有神经元，不进行随机丢弃

2. BatchNorm 层

   - **训练时**：使用当前批次的统计量（均值、方差）进行标准化

   - **评估时**：使用运行平均值（running mean）和运行方差（running variance）

### 特殊操作——`apply()`

好的，我们来详细讲解 PyTorch 中的 `apply()` 函数，这是一个非常重要且强大的工具。

#### 1. 什么是 `apply()` 函数？

`apply()` 是 PyTorch 中 `nn.Module` 类的一个方法，它能够**递归地对模型中的每个子模块应用一个指定的函数**。这意味着它会遍历网络中的所有层（包括嵌套的子模块），并对每个层执行相同的操作。

#### 2. 基本语法

```python
model.apply(fn)
```

- `model`: 你的神经网络模型（`nn.Module` 的实例）
- `fn`: 一个函数，这个函数接受一个模块作为参数，并对该模块进行操作
- **返回值**: 返回模型本身（允许链式调用）

#### 3. 工作原理

`apply()` 使用深度优先搜索（DFS）递归地遍历模型的所有子模块：

1. 对当前模块应用函数 `fn`
2. 递归地对所有子模块应用 `fn`
3. 继续对子模块的子模块应用 `fn`，直到遍历完所有模块

#### 4. 主要用途

##### 4.1 权重初始化（最常见用途）
```python
def init_weights(m):
    if isinstance(m, nn.Linear):
        nn.init.xavier_uniform_(m.weight)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode='fan_out')
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

model = MyNetwork()
model.apply(init_weights)  # 对所有层应用初始化函数
```

##### 4.2 自定义操作
```python
# 冻结所有批归一化层的参数
def freeze_bn(m):
    if isinstance(m, nn.BatchNorm2d):
        m.weight.requires_grad = False
        m.bias.requires_grad = False

model.apply(freeze_bn)

# 打印所有层的类型和参数数量
def print_layer_info(m):
    num_params = sum(p.numel() for p in m.parameters())
    print(f"{m.__class__.__name__}: {num_params} parameters")

model.apply(print_layer_info)
```

#### 4.3 设置训练/评估模式
```python
# 自定义训练模式设置
def set_custom_training_mode(m):
    if hasattr(m, 'custom_training_flag'):
        m.train(m.custom_training_flag)

model.apply(set_custom_training_mode)
```

## 4 `torch.optim`

### `torch.optim.SGD`

#### 1. 它是什么？

`torch.optim.SGD` 是 PyTorch 中实现**随机梯度下降（Stochastic Gradient Descent）** 算法的优化器类。它是深度学习中最基础、最核心的优化算法，许多更先进的优化器（如 Adam）都是基于 SGD 的改进。

#### 2. 核心思想

SGD 的核心思想很简单：**沿着损失函数的负梯度方向更新参数**，从而最小化损失函数。

基本更新公式：
```
param = param - learning_rate * param.grad
```

#### 3. 语法和参数

```python
torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, 
               weight_decay=0, nesterov=False, *, maximize=False)
```

**主要参数详解：**

| 参数               | 说明                                          | 默认值 |
| ------------------ | --------------------------------------------- | ------ |
| **`params`**       | 需要优化的参数（通常是 `model.parameters()`） | 必需   |
| **`lr`**           | **学习率** - 控制每次参数更新的步长           | 必需   |
| **`momentum`**     | **动量** - 加速收敛，减少振荡                 | 0      |
| **`weight_decay`** | **权重衰减** - L2 正则化系数                  | 0      |
| **`nesterov`**     | 是否使用 Nesterov 动量                        | False  |
| **`dampening`**    | 动量阻尼系数                                  | 0      |
| **`maximize`**     | 是否最大化目标函数（而不是最小化）            | False  |

#### 4. 基本用法示例

##### 示例 1：最简单的 SGD
```python
import torch
import torch.nn as nn
import torch.optim as optim

# 定义一个简单的模型
model = nn.Linear(10, 1)
criterion = nn.MSELoss()

# 创建SGD优化器（最基本的形式）
optimizer = optim.SGD(model.parameters(), lr=0.01)

# 模拟训练数据
x = torch.randn(5, 10)  # batch_size=5, features=10
y = torch.randn(5, 1)   # 目标值

# 训练步骤
for epoch in range(100):
    # 前向传播
    predictions = model(x)
    loss = criterion(predictions, y)
    
    # 反向传播
    optimizer.zero_grad()  # 清除之前的梯度
    loss.backward()        # 计算梯度
    
    # 参数更新
    optimizer.step()       # 执行SGD更新
    
    if epoch % 20 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')
```

#### 5. 动量（Momentum）的作用

动量帮助优化器在相关方向上加速，减少振荡。

##### 示例 2：使用动量的 SGD
```python
# 使用动量（通常设为0.9）
optimizer_with_momentum = optim.SGD(
    model.parameters(), 
    lr=0.01, 
    momentum=0.9
)

# 更新公式变为：
# v = momentum * v - lr * grad
# param = param + v
```

#### 6. 权重衰减（L2正则化）

权重衰减通过在损失函数中添加L2正则项来防止过拟合。

##### 示例 3：使用权重衰减
```python
# 添加权重衰减（L2正则化）
optimizer_with_wd = optim.SGD(
    model.parameters(), 
    lr=0.01, 
    weight_decay=1e-4  # 常用的权重衰减系数
)

# 这等价于在损失函数中添加：weight_decay * Σ(param^2)
```

#### 7. Nesterov 动量

Nesterov 动量是标准动量的改进版本，通常能提供更好的收敛性能。

##### 示例 4：使用 Nesterov 动量
```python
optimizer_nesterov = optim.SGD(
    model.parameters(),
    lr=0.01,
    momentum=0.9,
    nesterov=True  # 启用Nesterov动量
)
```

#### 8. 完整训练示例

##### 示例 5：完整的神经网络训练
```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# 1. 准备数据
x_train = torch.randn(1000, 10)
y_train = torch.randn(1000, 1)
dataset = TensorDataset(x_train, y_train)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# 2. 定义模型
model = nn.Sequential(
    nn.Linear(10, 50),
    nn.ReLU(),
    nn.Linear(50, 1)
)

# 3. 定义损失函数和优化器
criterion = nn.MSELoss()
optimizer = optim.SGD(
    model.parameters(),
    lr=0.01,           # 学习率
    momentum=0.9,       # 动量
    weight_decay=1e-4,  # 权重衰减
    nesterov=True       # Nesterov动量
)

# 4. 训练循环
num_epochs = 50
for epoch in range(num_epochs):
    epoch_loss = 0.0
    
    for batch_x, batch_y in dataloader:
        # 前向传播
        predictions = model(batch_x)
        loss = criterion(predictions, batch_y)
        
        # 反向传播
        optimizer.zero_grad()  # 重要：清除之前的梯度
        loss.backward()
        
        # 参数更新
        optimizer.step()
        
        epoch_loss += loss.item()
    
    avg_loss = epoch_loss / len(dataloader)
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')
```

#### 9. 学习率调度

通常需要随着训练进行调整学习率。

##### 示例 6：学习率调度
```python
from torch.optim.lr_scheduler import StepLR

optimizer = optim.SGD(model.parameters(), lr=0.1)

# 每30个epoch将学习率乘以0.1
scheduler = StepLR(optimizer, step_size=30, gamma=0.1)

for epoch in range(100):
    # 训练步骤...
    train(...)
    
    # 更新学习率
    scheduler.step()
    
    current_lr = optimizer.param_groups[0]['lr']
    print(f'Epoch {epoch}, Learning Rate: {current_lr}')
```

#### 10. 参数组（Parameter Groups）

可以对不同的参数设置不同的超参数。

##### 示例 7：不同的参数不同的学习率
```python
# 获取模型的参数
params = list(model.named_parameters())

# 为不同层设置不同的学习率
optimizer = optim.SGD([
    {'params': model[0].parameters(), 'lr': 0.01},  # 第一层
    {'params': model[2].parameters(), 'lr': 0.001}  # 第三层
], momentum=0.9)
```

#### 11. SGD 的变体和技巧

##### 示例 8：带动量的SGD实际效果
```python
# 对比有动量和没有动量的收敛速度
model1 = nn.Linear(10, 1)
model2 = nn.Linear(10, 1)

optimizer_no_momentum = optim.SGD(model1.parameters(), lr=0.01)
optimizer_with_momentum = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)

# 通常 optimizer_with_momentum 会收敛得更快
```

